{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa \n",
    "import h5py\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2628 records, 5 chunks of length 4410 each\n"
     ]
    }
   ],
   "source": [
    "# открывать h5 файлы надо специальным классом\n",
    "with h5py.File('../files/train.h5') as f:\n",
    "    chunks_shape = f[\"chunks\"].shape\n",
    "    print(f\"Loaded {chunks_shape[0]} records, {chunks_shape[1]} \"\n",
    "          f\"chunks of length {chunks_shape[2]} each\")\n",
    "    # выберем только первые 2 фрагмента из каждой аудиозаписи\n",
    "    train_2c_x = np.ndarray((chunks_shape[0], 2, chunks_shape[2]), dtype=float)\n",
    "    for i, record in enumerate(f[\"chunks\"]):\n",
    "        train_2c_x[i] = record[0:2, :]\n",
    "    # выгружаем метки классов\n",
    "    raw_train_y = np.array(f[\"classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class encoding {b'Sound_Drum': 0, b'Sound_Guitar': 1, b'Sound_Piano': 2, b'Sound_Violin': 3}\n"
     ]
    }
   ],
   "source": [
    "# закодируем классы числами 0-3\n",
    "class_encoding = {v: i for i, v in enumerate(np.unique(raw_train_y))}\n",
    "print(\"Class encoding:\", class_encoding)\n",
    "# создадим функцию, которая будет кодировать классы для np.ndarray\n",
    "encode_y = np.vectorize(class_encoding.get)\n",
    "# закодируем считанные `y`\n",
    "train_y = encode_y(raw_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генератор функций, которая будет извлекать нужные фичи из кусочков\n",
    "\n",
    "def create_feature_mapper(n_mfcc: int, n_contrast: int, n_chroma: int):\n",
    "    def extract_features(chunks: np.ndarray) -> np.ndarray:\n",
    "        length = n_mfcc + n_contrast + n_mfcc\n",
    "        n_chunks = chunks.shape[0]\n",
    "        x = np.ndarray((n_chunks, length))\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            c = 0\n",
    "            if n_mfcc > 0:\n",
    "                x[i,:n_mfcc] = np.mean(\n",
    "                    librosa.feature.mfcc(y=chunk, n_mfcc=n_mfcc), \n",
    "                    1)\n",
    "                c += n_mfcc\n",
    "            if n_contrast > 1:\n",
    "                x[i, c : c + n_contrast] = np.mean(\n",
    "                    librosa.feature.spectral_contrast(y=chunk, n_bands=n_contrast - 1),\n",
    "                    1)\n",
    "                c += n_contrast\n",
    "            if n_chroma > 0:\n",
    "                x[i, c : c + n_chroma] = np.mean(\n",
    "                    librosa.feature.chroma_cens(y=chunk, n_chroma=n_chroma),\n",
    "                    1)\n",
    "        return x.reshape(length * n_chunks)\n",
    "    return extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper1 = create_feature_mapper(10, 7, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vova/.local/lib/python3.10/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=1024 is too large for input signal of length=552\n",
      "  warnings.warn(\n",
      "/home/vova/.local/lib/python3.10/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=1024 is too large for input signal of length=276\n",
      "  warnings.warn(\n",
      "/home/vova/.local/lib/python3.10/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=1024 is too large for input signal of length=138\n",
      "  warnings.warn(\n",
      "/home/vova/.local/lib/python3.10/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=1024 is too large for input signal of length=69\n",
      "  warnings.warn(\n",
      "/home/vova/.local/lib/python3.10/site-packages/librosa/core/pitch.py:102: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.67013083e+02,  2.64743504e+00,  5.98910195e+01, ...,\n",
       "         2.24494835e-01,  2.24685239e-01,  2.24906156e-01],\n",
       "       [-3.99005107e+02,  1.87495548e+02, -3.17588595e+01, ...,\n",
       "         2.24494835e-01,  2.24685239e-01,  2.24906156e-01],\n",
       "       [-3.12242263e+02,  1.76721839e+02, -3.85841875e+01, ...,\n",
       "         1.84834065e-02,  1.75508422e-02,  1.66043270e-02],\n",
       "       ...,\n",
       "       [-3.11975553e+02,  2.41897188e+01, -1.09888666e+02, ...,\n",
       "         5.66833063e-01,  5.66870817e-01,  5.66904186e-01],\n",
       "       [-6.53860950e+02,  1.12662655e+02,  5.13715328e+01, ...,\n",
       "         2.33843785e-01,  2.33746484e-01,  2.33651006e-01],\n",
       "       [-5.19174017e+02,  3.46728566e+01, -2.40452995e+01, ...,\n",
       "         7.91321065e-02,  7.91975249e-02,  7.92984824e-02]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1 = np.array(list(map(mapper1, train_2c_x)))\n",
    "train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 80 records, 5 chunks of length 4410 each\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('../files/test.h5') as f:\n",
    "    chunks_shape = f[\"chunks\"].shape\n",
    "    print(f\"Loaded {chunks_shape[0]} records, {chunks_shape[1]} \"\n",
    "          f\"chunks of length {chunks_shape[2]} each\")\n",
    "    # выберем только первые 2 фрагмента из каждой аудиозаписи\n",
    "    test_2c_x = np.ndarray((chunks_shape[0], 2, chunks_shape[2]), dtype=float)\n",
    "    for i, record in enumerate(f[\"chunks\"]):\n",
    "        test_2c_x[i] = record[0:2, :]\n",
    "    # выгружаем метки классов\n",
    "    raw_test_y = np.array(f[\"classes\"])\n",
    "test_y = encode_y(raw_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vova/.local/lib/python3.10/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=1024 is too large for input signal of length=552\n",
      "  warnings.warn(\n",
      "/home/vova/.local/lib/python3.10/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=1024 is too large for input signal of length=276\n",
      "  warnings.warn(\n",
      "/home/vova/.local/lib/python3.10/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=1024 is too large for input signal of length=138\n",
      "  warnings.warn(\n",
      "/home/vova/.local/lib/python3.10/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=1024 is too large for input signal of length=69\n",
      "  warnings.warn(\n",
      "/home/vova/.local/lib/python3.10/site-packages/librosa/core/pitch.py:102: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    }
   ],
   "source": [
    "test1 = np.array(list(map(mapper1, test_2c_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "rfc.fit(train1, train_y)\n",
    "predicted_y = rfc.predict(test1)\n",
    "sum(predicted_y == test_y) / len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7625"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.SVC(random_state=42)\n",
    "svc.fit(train1, train_y)\n",
    "predicted_y = svc.predict(test1)\n",
    "sum(predicted_y == test_y) / len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vova/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, ..., 0, 1, 3], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=4).fit(train1)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "def cluster_accuracy(clusters, gt, n_classes):\n",
    "    accuracies = []\n",
    "    for p in permutations(range(n_classes)):\n",
    "        mapped = np.vectorize({i: x for i, x in enumerate(p)}.get)(clusters)\n",
    "        accuracies.append(sum(mapped == gt))\n",
    "    return max(accuracies) / len(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4341704718417047"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_accuracy(kmeans.labels_, train_y, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('../files/mapped_data1.h5', 'w') as f:\n",
    "    # train_x и test_x - выделенные фичи (вычисленные коэффициенты), train_y и test_y - метки \n",
    "    f.create_dataset(\"train_x\", data=train1)\n",
    "    f.create_dataset(\"train_y\", data=train_y)\n",
    "    f.create_dataset(\"test_x\", data=test1)\n",
    "    f.create_dataset(\"test_y\", data=test_y)\n",
    "    f.attrs['n_mfcc'] = 10\n",
    "    f.attrs['n_contrast'] = 7\n",
    "    f.attrs['n_chroma'] = 6\n",
    "    f.attrs['n_chunks'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('../files/mapped_data1.h5') as f:\n",
    "    train1  = np.array(f[\"train_x\"])\n",
    "    train_y = np.array(f[\"train_y\"])\n",
    "    test1   = np.array(f[\"test_x\"])\n",
    "    test_y  = np.array(f[\"test_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_x = scaler.fit_transform(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vova/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, ..., 3, 0, 3], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=4).fit(scaled_x)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6301369863013698"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_accuracy(kmeans.labels_, train_y, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>135</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>303</td>\n",
       "      <td>438</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>397</td>\n",
       "      <td>104</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>158</td>\n",
       "      <td>30</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1    2    3\n",
       "row_0                    \n",
       "0      258  135    9    1\n",
       "1       25  303  438    7\n",
       "2      397  104   51    6\n",
       "3       20  158   30  686"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(kmeans.labels_, train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
