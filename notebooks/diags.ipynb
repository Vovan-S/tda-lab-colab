{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PairwiseDistance\n",
    "from gtda.time_series import SingleTakensEmbedding\n",
    "\n",
    "from itertools import chain\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройка параметров для вложения Такенса\n",
    "TIME_DELAY = 14\n",
    "\n",
    "embedder = SingleTakensEmbedding(\n",
    "    parameters_type='fixed', \n",
    "    time_delay=TIME_DELAY,\n",
    "    dimension=3)\n",
    "ripser = VietorisRipsPersistence(homology_dimensions=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('../files/train.h5') as f:\n",
    "    chunks_train = np.array(f[\"chunks\"])\n",
    "    names_train  = np.array(f[\"filenames\"])\n",
    "    classes_train = np.array(f[\"classes\"])\n",
    "\n",
    "with h5py.File('../files/test.h5') as f:\n",
    "    chunks_test = np.array(f[\"chunks\"])\n",
    "    names_test  = np.array(f[\"filenames\"])\n",
    "    classes_test = np.array(f[\"classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Каждый аудиофайл был нарезан на 5 фрагментов по 200 мс. Берутся 500 первых точек первого фрагмента каждого файла.\n",
    "tss = [embedder.fit_transform(ch[0, :500]) for ch in chain(chunks_train, chunks_test)]\n",
    "name = list(chain(names_train, names_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строятся диаграммы персистентности для каждого из 2628 фрагментов по 500 точек\n",
    "diags = ripser.fit_transform(tss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение диаграмм в файл diags-all-14.h5\n",
    "with h5py.File(f'../files/diags-all-{TIME_DELAY}.h5', mode='w') as f:\n",
    "    d = f.create_dataset(\"diagrams\", data=diags)\n",
    "    d.attrs['takens-time-delay'] = TIME_DELAY\n",
    "    d.attrs['chunk-size'] = 500\n",
    "    f.create_dataset(\"filenames\", data=name)\n",
    "    f.create_dataset(\"classes\", data=np.append(classes_train, classes_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.append(classes_train, classes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Случайным образом выбираем по 5 экземпляров каждого класса из обучающего множества (сохраняем индексы)\n",
    "unique_classes = np.unique(classes)\n",
    "chosen = []\n",
    "k = 5\n",
    "for c in unique_classes:\n",
    "    ind = choices([i for i, c2 in enumerate(classes_train) if c == c2], k = k)\n",
    "    chosen.extend(ind)\n",
    "chosen = np.array(chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  66, 1791, 1258, 1730, 1129, 1766, 2337, 2147, 1766, 2447, 2171,\n",
       "       2523, 1966,  802,  149, 2585, 1743, 1284, 2250, 1486])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with h5py.File('../files/metrics-train-all.h5') as f:\n",
    "    chosen = np.array(f[\"reference-index\"])\n",
    "chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw  = PairwiseDistance(metric='wasserstein', order=None)\n",
    "dbn = PairwiseDistance(metric='bottleneck', order=None)\n",
    "dbc = PairwiseDistance(metric='betti', order=None)\n",
    "dls = PairwiseDistance(metric='landscape', order=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_diags = diags[chosen]\n",
    "# Последние 80 диаграмм относятся к тестовому множеству\n",
    "test_diags = diags[-80:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставляем только диаграммы, относящиеся к обучающему множеству, и не выбранные ранее\n",
    "full_train_diags = np.delete(diags[:-80], chosen, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 2625, 2626, 2627])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_indexes = np.array([i for i in range(diags.shape[0] - 80) if i not in chosen])\n",
    "full_train_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f'../files/metrics-train-all-{TIME_DELAY}.h5', mode='w') as f:\n",
    "    f.create_dataset(\"reference-index\", data=chosen)\n",
    "    f.create_dataset(\"train-index\", data=full_train_indexes)\n",
    "    for d in [dw, dbn, dbc, dls]:\n",
    "# Вычисляем расстояния от выбранных 20 диаграмм до всех оставшихся из обучающего множества\n",
    "        d.fit(chosen_diags)\n",
    "        matrix = d.transform(full_train_diags)\n",
    "        f.create_dataset(d.get_params()['metric'], data=matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f'../files/metrics-test-{TIME_DELAY}.h5', mode='w') as f:\n",
    "    f.create_dataset(\"reference-index\", data=chosen)\n",
    "    f.create_dataset(\"test-index\", data=np.array(range(diags.shape[0]-80, diags.shape[0])))\n",
    "    for d in [dw, dbn, dbc, dls]:\n",
    "# Вычисляем расстояния от выбранных 20 диаграмм до всех диаграмм из тестового множества\n",
    "        d.fit(chosen_diags)\n",
    "        matrix = d.transform(test_diags)\n",
    "        f.create_dataset(d.get_params()['metric'], data=matrix)"
   ]
  },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
